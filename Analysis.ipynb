{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f6a57-b219-4dda-ad0e-476d9443ab4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44d0c2-b090-45eb-821e-7ca9ff0037d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf96a84f-a6a0-4f99-b0ca-86d65dddb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting the files if something is present in that folder\n",
    "import os\n",
    "\n",
    "folder_path = r\"D:\\ANALYTICS PROJECT\\Output folder\"\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)  # Delete the file\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7255ea8-7b1d-4551-a725-02e43a13fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines :6990280,Lines per file : 174757\n",
      "task is completed\n"
     ]
    }
   ],
   "source": [
    "input_file= r\"D:\\ANALYTICS PROJECT\\Yelp-JSON\\Yelp JSON\\yelp_dataset\\yelp_academic_dataset_review.json\"\n",
    "output_folder=r\"D:\\ANALYTICS PROJECT\\Output folder\"\n",
    "output_prefix=\"split_string_\"\n",
    "num_files=40\n",
    "\n",
    "\n",
    "with open (input_file,\"r\",encoding=\"utf8\") as file:  # opening the input file \n",
    "    Total_lines=sum(1 for i in file) #counting the total lines present in that file\n",
    "    no_of_lines= Total_lines//num_files #no. of lines to be present in each file\n",
    "\n",
    "print(f\"Total lines :{Total_lines},Lines per file : {no_of_lines}\")\n",
    "\n",
    "with open (input_file,\"r\",encoding=\"utf-8\") as file:\n",
    "    for i in range(num_files):\n",
    "        output_file= os.path.join(output_folder,f\"{output_prefix}{i+1}.json\")\n",
    "        with open (output_file,\"w\",encoding=\"utf-8\") as out_file:\n",
    "            for k in range(no_of_lines):\n",
    "                line=file.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                out_file.write(line)\n",
    "print(\"task is completed\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d282514-d9fe-45be-8653-b4e9f31db827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.37.37)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.37 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3) (1.37.37)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3) (0.11.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.38.0,>=1.37.37->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.38.0,>=1.37.37->boto3) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.37->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e56c65c-f680-43c0-8a54-c78a11385c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_1.json to s3://end-to-end-analytics-project-sp/from_local/split_string_1.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_10.json to s3://end-to-end-analytics-project-sp/from_local/split_string_10.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_11.json to s3://end-to-end-analytics-project-sp/from_local/split_string_11.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_12.json to s3://end-to-end-analytics-project-sp/from_local/split_string_12.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_13.json to s3://end-to-end-analytics-project-sp/from_local/split_string_13.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_14.json to s3://end-to-end-analytics-project-sp/from_local/split_string_14.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_15.json to s3://end-to-end-analytics-project-sp/from_local/split_string_15.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_16.json to s3://end-to-end-analytics-project-sp/from_local/split_string_16.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_17.json to s3://end-to-end-analytics-project-sp/from_local/split_string_17.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_18.json to s3://end-to-end-analytics-project-sp/from_local/split_string_18.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_19.json to s3://end-to-end-analytics-project-sp/from_local/split_string_19.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_2.json to s3://end-to-end-analytics-project-sp/from_local/split_string_2.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_20.json to s3://end-to-end-analytics-project-sp/from_local/split_string_20.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_21.json to s3://end-to-end-analytics-project-sp/from_local/split_string_21.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_22.json to s3://end-to-end-analytics-project-sp/from_local/split_string_22.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_23.json to s3://end-to-end-analytics-project-sp/from_local/split_string_23.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_24.json to s3://end-to-end-analytics-project-sp/from_local/split_string_24.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_25.json to s3://end-to-end-analytics-project-sp/from_local/split_string_25.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_26.json to s3://end-to-end-analytics-project-sp/from_local/split_string_26.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_27.json to s3://end-to-end-analytics-project-sp/from_local/split_string_27.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_28.json to s3://end-to-end-analytics-project-sp/from_local/split_string_28.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_29.json to s3://end-to-end-analytics-project-sp/from_local/split_string_29.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_3.json to s3://end-to-end-analytics-project-sp/from_local/split_string_3.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_30.json to s3://end-to-end-analytics-project-sp/from_local/split_string_30.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_31.json to s3://end-to-end-analytics-project-sp/from_local/split_string_31.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_32.json to s3://end-to-end-analytics-project-sp/from_local/split_string_32.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_33.json to s3://end-to-end-analytics-project-sp/from_local/split_string_33.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_34.json to s3://end-to-end-analytics-project-sp/from_local/split_string_34.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_35.json to s3://end-to-end-analytics-project-sp/from_local/split_string_35.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_36.json to s3://end-to-end-analytics-project-sp/from_local/split_string_36.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_37.json to s3://end-to-end-analytics-project-sp/from_local/split_string_37.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_38.json to s3://end-to-end-analytics-project-sp/from_local/split_string_38.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_39.json to s3://end-to-end-analytics-project-sp/from_local/split_string_39.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_4.json to s3://end-to-end-analytics-project-sp/from_local/split_string_4.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_40.json to s3://end-to-end-analytics-project-sp/from_local/split_string_40.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_5.json to s3://end-to-end-analytics-project-sp/from_local/split_string_5.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_6.json to s3://end-to-end-analytics-project-sp/from_local/split_string_6.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_7.json to s3://end-to-end-analytics-project-sp/from_local/split_string_7.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_8.json to s3://end-to-end-analytics-project-sp/from_local/split_string_8.json\n",
      "Uploading D:\\ANALYTICS PROJECT\\Output folder\\split_string_9.json to s3://end-to-end-analytics-project-sp/from_local/split_string_9.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# --- Step 1: Configuration ---\n",
    "local_folder = r\"D:\\ANALYTICS PROJECT\\Output folder\"  # Change this to your local folder\n",
    "bucket_name = 'end-to-end-analytics-project-sp'     # Your target S3 bucket\n",
    "s3_folder_prefix = 'from_local'  # Optional: the folder inside the bucket\n",
    "\n",
    "# --- Step 2: Connect to S3 ---\n",
    "# If running on a system with pre-configured AWS credentials (e.g., EC2, Sagemaker, ~/.aws/credentials), no need to set keys manually\n",
    "s3 = s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='***********',\n",
    "    aws_secret_access_key='*************',\n",
    "    region_name='*********'  # Example: 'us-east-1'\n",
    ")\n",
    " # You can add region_name='us-east-1' if needed\n",
    "\n",
    "# --- Step 3: Upload files recursively ---\n",
    "def upload_folder_to_s3(local_folder, bucket, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_path, local_folder)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")  # For Windows paths\n",
    "\n",
    "            print(f'Uploading {local_path} to s3://{bucket}/{s3_key}')\n",
    "            s3.upload_file(local_path, bucket, s3_key)\n",
    "\n",
    "# --- Run the upload ---\n",
    "upload_folder_to_s3(local_folder, bucket_name, s3_folder_prefix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fe2df-90a7-4888-8861-1852bb3e1dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
